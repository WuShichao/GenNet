"""
Function to load in unecessarily long waveforms generated by Daniel Williams
and then to downsample them to ~8kHz.
"""

import numpy as np
import argparse
import glob
import pickle
from scipy.signal import resample

def get_args():
    parser = argparse.ArgumentParser(prog='nn.py', description='Generative Adversarial Neural Network in keras with tensorflow')

    # arguments
    parser.add_argument('--datadir', type=str, default='/home/hunter.gabbard/Burst/rricard_gan/data/data/sg/F70Q100-elliptical',
                        help='directory where data txt files are stored in. Please provide FULL path.')
    parser.add_argument('--n-samples', type=int, default='1000',
                        help='number of waveforms and noise samples to train over (e.g. 10000 would mean 10000 noise and 10000 waveforms signals, 20000 in total.')

    return parser.parse_args()

def load_data(path,n_samples):
    """
    Loads txt files into a numpy array called data.
    """
    for counter,filename in enumerate(glob.iglob('%s/*.txt' % path)):
        print("Loading waveform #{}".format(counter))
        if counter == 0:
            data = np.loadtxt(filename)
            data = resample(data, 8192)
            data /= np.max(data)
            # plot first waveform in training set
            #plt.plot(data)
            #plt.savefig('/home/hunter.gabbard/public_html/Burst/sine-gaussian_runs/resampled_waveform.png')
            #plt.close()
        elif counter == n_samples:
            break
        else:
            data_new = np.loadtxt(filename)
            data_new = resample(data_new, 8192)
            data_new /= np.max(data_new)
            data = np.vstack((data,data_new))


    return data

args = get_args()

data = load_data(args.datadir,args.n_samples)

# dump data in a pickle file
pickle_out = open("data.pkl", "wb")
pickle.dump(data, pickle_out)
pickle_out.close()
